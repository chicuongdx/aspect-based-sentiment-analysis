{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bilstm_crf import BiLSTMCRF\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load embedding\n",
    "embedding_maxtrix = np.load('embedding/embedding_matrix.npy')\n",
    "\n",
    "# load vocab\n",
    "with open('data/vocab.txt', 'r') as f:\n",
    "    vocab = f.read().split('\\n')\n",
    "len(vocab)\n",
    "\n",
    "# load tag_to_id\n",
    "with open('data/tag_to_id.json', 'r') as f:\n",
    "    tag_to_id = json.load((f))\n",
    "\n",
    "# load train and dev data\n",
    "TRAIN_PATH = 'data/span_detection_datasets_IOB/train.json'\n",
    "DEV_PATH = 'data/span_detection_datasets_IOB/dev.json'\n",
    "\n",
    "with open(TRAIN_PATH, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(DEV_PATH, 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "train_sentences = list(train_data['text'].values())\n",
    "dev_sentences = list(dev_data['text'].values())\n",
    "\n",
    "train_labels = list(train_data['labels'].values())\n",
    "dev_labels = list(dev_data['labels'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert data to ids\n",
    "def convert_to_ids(data, vocab, max_len=256):\n",
    "    id_data = []\n",
    "\n",
    "    pad_token_id = vocab.index('<PAD>')\n",
    "    ukn_token_id = vocab.index('<UNK>')\n",
    "    for sentence in data:\n",
    "        ids = []\n",
    "        for word in sentence.split():\n",
    "            if word in vocab:\n",
    "                ids.append(vocab.index(word))\n",
    "            else:\n",
    "                ids.append(ukn_token_id)\n",
    "\n",
    "        if len(ids) < max_len:\n",
    "            ids += [pad_token_id] * (max_len - len(ids))\n",
    "        id_data.append(np.array(ids))\n",
    "        \n",
    "    return id_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = convert_to_ids(train_sentences, vocab)\n",
    "dev_tokenized = convert_to_ids(dev_sentences, vocab)\n",
    "\n",
    "train_tokenized = [torch.LongTensor(tokenized) for tokenized in train_tokenized]\n",
    "dev_tokenized = [torch.LongTensor(tokenized) for tokenized in dev_tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tag_to_id\n",
    "with open('data/tag_to_id.json', 'r') as f:\n",
    "    tag_to_id = json.load((f))\n",
    "\n",
    "# Convert labels to ids\n",
    "# labels = [[start, end, tag], ...]\n",
    "def convert_labels_to_ids(label, tag_to_id, max_len=256):\n",
    "    ids = [tag_to_id[tag] for tag in label]\n",
    "\n",
    "    if len(ids) < max_len:\n",
    "        ids += [tag_to_id['O']] * (max_len - len(ids))\n",
    "        \n",
    "    return np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_encoding = np.array([convert_labels_to_ids(label, tag_to_id) for label in train_labels])\n",
    "dev_labels_encoding = np.array([convert_labels_to_ids(label, tag_to_id) for label in dev_labels])\n",
    "\n",
    "train_labels_encoding = np.expand_dims(train_labels_encoding, axis=2)\n",
    "dev_labels_encoding = np.expand_dims(dev_labels_encoding, axis=2)\n",
    "\n",
    "train_labels_encoding = [torch.LongTensor(label) for label in train_labels_encoding]\n",
    "dev_labels_encoding = [torch.LongTensor(label) for label in dev_labels_encoding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_detection_model = BiLSTMCRF(vocab_size=len(vocab), tag_to_ix=tag_to_id, hidden_dim=200, embedding_maxtrix=embedding_maxtrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "forward_score:  tensor(-789.1182, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hii\\miniconda3\\envs\\udemy\\Lib\\site-packages\\TorchCRF\\__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorCompare.cpp:493.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_score:  tensor([-789.1182], grad_fn=<SubBackward0>)\n",
      "loss: 0.0\n",
      "forward_score:  tensor(-790.2479, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2479], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.3355, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.3355], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.6654, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.6654], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.9197, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.9197], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.2810, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.2810], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.6131, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.6131], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.9012, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.9012], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0895, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0895], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.8305, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.8305], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.9872, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.9872], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.1389, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.1389], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.7550, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.7550], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.4105, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.4105], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.3011, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.3011], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9912, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9912], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-792.6816, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-792.6816], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.1462, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.1462], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-787.7505, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-787.7505], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.3409, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.3409], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2430, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2430], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.3481, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.3481], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1264, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1264], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.5468, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.5468], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0977, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0977], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0615, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0615], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.5594, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.5594], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.8810, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.8810], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.4236, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.4236], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.2866, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.2866], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.7283, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.7283], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.9806, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.9806], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2673, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2673], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.3822, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.3822], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.7426, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.7426], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7891, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7891], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.4421, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.4421], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0237, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0237], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.4651, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.4651], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0488, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0488], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.3495, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.3495], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8546, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8546], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.8011, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.8011], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.2418, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.2418], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1177, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1177], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0606, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0606], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6647, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6647], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1911, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1911], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-787.6218, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-787.6218], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.0005, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.0005], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.8242, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.8242], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6827, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6827], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9158, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9158], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.3963, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.3963], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2690, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2690], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7114, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7114], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2950, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2950], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2510, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2510], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.4443, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.4443], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1068, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1068], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6349, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6349], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.5881, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.5881], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1002, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1002], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.1920, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.1920], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.3544, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.3544], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6149, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6149], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.2245, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.2245], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0366, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0366], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.1494, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.1494], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.8297, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.8297], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0598, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0598], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.3559, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.3559], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.2392, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.2392], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.8702, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.8702], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8205, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8205], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.9717, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.9717], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.4123, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.4123], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1663, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1663], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0546, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0546], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.8489, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.8489], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6880, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6880], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.3724, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.3724], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-786.7851, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-786.7851], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6385, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6385], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8791, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8791], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.1479, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.1479], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.6772, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.6772], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.2577, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.2577], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7885, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7885], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.6328, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.6328], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.4424, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.4424], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6180, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6180], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.4283, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.4283], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1103, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1103], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.4286, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.4286], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8635, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8635], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.7891, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.7891], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-786.5872, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-786.5872], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-787.5743, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-787.5743], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.1718, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.1718], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9365, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9365], grad_fn=<SubBackward0>)\n",
      "loss: 0.0\n",
      "forward_score:  tensor(-789.9224, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9224], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.4489, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.4489], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9758, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9758], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.3298, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.3298], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.5275, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.5275], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-786.0765, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-786.0765], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1667, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1667], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7135, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7135], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.8410, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.8410], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.5907, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.5907], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0238, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0238], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.7181, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.7181], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2447, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2447], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1445, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1445], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.6654, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.6654], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-787.9041, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-787.9041], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.3284, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.3284], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1102, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1102], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2031, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2031], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0652, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0652], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.0427, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.0427], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.3635, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.3635], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1956, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1956], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.0776, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.0776], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7960, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7960], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-785.4266, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-785.4266], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7813, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7813], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.5697, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.5697], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2380, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2380], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.9949, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.9949], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2445, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2445], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.3564, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.3564], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-792.7370, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-792.7370], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1586, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1586], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0325, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0325], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9869, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9869], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2933, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2933], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.4481, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.4481], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.8808, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.8808], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.6387, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.6387], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.4200, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.4200], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.2825, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.2825], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8636, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8636], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.4072, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.4072], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0570, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0570], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0919, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0919], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.9503, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.9503], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.2882, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.2882], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7501, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7501], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7897, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7897], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.9683, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.9683], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7156, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7156], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-787.8787, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-787.8787], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.4548, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.4548], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0481, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0481], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.1802, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.1802], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6522, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6522], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8900, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8900], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.9792, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.9792], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6635, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6635], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2994, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2994], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1467, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1467], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.4246, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.4246], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.9072, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.9072], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7621, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7621], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-787.3986, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-787.3986], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.6007, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.6007], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1198, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1198], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7177, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7177], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1847, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1847], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7335, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7335], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.3320, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.3320], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.1703, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.1703], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2011, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2011], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8177, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8177], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2785, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2785], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7708, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7708], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0558, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0558], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7221, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7221], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7782, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7782], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.3492, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.3492], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0324, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0324], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.0225, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.0225], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.9466, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.9466], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9886, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9886], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9031, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9031], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.5104, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.5104], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.1263, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.1263], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8353, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8353], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8951, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8951], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0320, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0320], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-785.9264, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-785.9264], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0945, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0945], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0461, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0461], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.5518, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.5518], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.5301, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.5301], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9909, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9909], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6146, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6146], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.5372, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.5372], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.4478, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.4478], grad_fn=<SubBackward0>)\n",
      "loss: 0.0\n",
      "forward_score:  tensor(-790.9197, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.9197], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0378, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0378], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6829, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6829], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8264, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8264], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.8828, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.8828], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6923, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6923], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-785.2209, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-785.2209], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.0172, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.0172], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-786.6251, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-786.6251], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0069, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0069], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.1284, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.1284], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.2393, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.2393], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-792.6290, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-792.6290], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.1943, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.1943], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7527, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7527], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.3488, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.3488], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.6905, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.6905], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-787.2227, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-787.2227], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6971, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6971], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8458, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8458], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1679, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1679], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.5232, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.5232], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.1829, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.1829], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.3380, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.3380], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8786, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8786], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1330, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1330], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.5734, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.5734], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7621, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7621], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0649, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0649], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8155, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8155], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7318, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7318], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-786.8123, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-786.8123], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7770, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7770], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-786.5942, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-786.5942], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.9626, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.9626], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.2578, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.2578], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9871, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9871], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.2916, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.2916], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8063, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8063], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.8497, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.8497], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.5420, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.5420], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9759, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9759], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.9012, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.9012], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8995, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8995], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7589, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7589], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.7869, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.7869], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0786, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0786], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.0005, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.0005], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.0014, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.0014], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0817, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0817], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0874, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0874], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.6432, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.6432], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.9313, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.9313], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.5601, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.5601], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8169, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8169], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0797, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0797], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.4763, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.4763], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9373, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9373], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1479, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1479], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7890, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7890], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1637, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1637], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7316, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7316], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2955, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2955], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-792.1561, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-792.1561], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9402, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9402], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.2991, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.2991], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.7426, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.7426], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.8406, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.8406], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7145, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7145], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7418, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7418], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2510, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2510], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.2073, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.2073], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.1451, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.1451], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.6592, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.6592], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.1487, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.1487], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-787.6386, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-787.6386], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.6796, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.6796], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.7078, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.7078], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.4088, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.4088], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.9028, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.9028], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.6718, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.6718], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-786.4421, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-786.4421], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.1509, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.1509], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.0255, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.0255], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0946, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0946], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.5141, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.5141], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.9903, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.9903], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.5969, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.5969], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.0213, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.0213], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.7192, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.7192], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.0018, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.0018], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1299, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1299], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.3417, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.3417], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.8012, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.8012], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.5648, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.5648], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.9789, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.9789], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.1450, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.1450], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.1302, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.1302], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-787.5482, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-787.5482], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1868, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1868], grad_fn=<SubBackward0>)\n",
      "loss: 0.0\n",
      "forward_score:  tensor(-786.8565, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-786.8565], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-789.5711, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-789.5711], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1552, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1552], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.2503, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.2503], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.1324, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.1324], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-791.5578, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-791.5578], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.9835, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.9835], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.4384, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.4384], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-788.0923, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-788.0923], grad_fn=<SubBackward0>)\n",
      "forward_score:  tensor(-790.7940, grad_fn=<SumBackward0>)\n",
      "gold_score:  tensor([-790.7940], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\CLOUDX\\Courses\\nlp\\aspect-based-sentiment-analysis\\train.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m span_detection_model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m span_detection_model\u001b[39m.\u001b[39mneg_log_likelihood(sentence, label)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Hii\\miniconda3\\envs\\udemy\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hii\\miniconda3\\envs\\udemy\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "optimizer = optim.SGD(span_detection_model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "epoch_num = 10\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print('epoch: {}'.format(epoch))\n",
    "    for i in range(len(train_tokenized)):\n",
    "        sentence = train_tokenized[i]\n",
    "        label = train_labels_encoding[i]\n",
    "        span_detection_model.zero_grad()\n",
    "        loss = span_detection_model.neg_log_likelihood(sentence, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print('loss: {}'.format(loss.item()))\n",
    "\n",
    "    # dev test\n",
    "    # with torch.no_grad():\n",
    "    #     for i in range(len(dev_sentences)):\n",
    "    #         sentence = dev_sentences[i]\n",
    "    #         label = dev_labels_encoding[i]\n",
    "    #         span_detection_model.zero_grad()\n",
    "    #         loss = span_detection_model.neg_log_likelihood(sentence, label)\n",
    "    #         loss.backward()\n",
    "    #         optimizer.step()\n",
    "    #         if i % 100 == 0:\n",
    "    #             print('loss: {}'.format(loss.item()))\n",
    "\n",
    "# save model\n",
    "# torch.save(span_detection_model.state_dict(), 'model/span_detection_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
