{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hii\\miniconda3\\envs\\absa\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/span_detection_datasets_split_word_IOB/train.jsonl'\n",
    "DEV_PATH = 'data/span_detection_datasets_split_word_IOB/dev.jsonl'\n",
    "TEST_PATH = 'data/span_detection_datasets_split_word_IOB/test.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function read jsonl file as dataframe\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def read_jsonl_to_dataframe(file_path):\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                json_obj = json.loads(line)\n",
    "                data.append(json_obj)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipping invalid JSON: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load embedding\n",
    "# embedding_maxtrix = np.load('embedding/embedding_matrix.npy')\n",
    "\n",
    "# load vocab\n",
    "# with open('data/vocab.txt', 'r') as f:\n",
    "#     vocab = f.read().split('\\n')\n",
    "\n",
    "# load tag_to_id\n",
    "with open('data/tag_to_id.json', 'r') as f:\n",
    "    tag_to_id = json.load((f))\n",
    "\n",
    "# load train and dev data\n",
    "\n",
    "train_data = read_jsonl_to_dataframe(TRAIN_PATH)\n",
    "dev_data = read_jsonl_to_dataframe(DEV_PATH)\n",
    "\n",
    "\n",
    "train_sentences = list(train_data.text.apply(lambda x: \" \".join(x)))\n",
    "dev_sentences = list(dev_data.text.apply(lambda x: \" \".join(x)))\n",
    "\n",
    "train_labels = list(train_data.labels)\n",
    "dev_labels = list(dev_data.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTH_TOKEN = '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'\n",
    "TOKENIZER_PATH = 'nguyenvulebinh/vi-mrc-large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this solution we use pretrained tokenizer from [HuggingFace](https://huggingface.co/nguyenvulebinh/vi-mrc-large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, use_fast=True)\n",
    "\n",
    "class SpanDetectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sentences, labels, tag_to_id, tokenizer, max_len=MAX_LEN):\n",
    "\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # encode all sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoded_sentences = self.tokenizer.batch_encode_plus(\n",
    "            self.sentences,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            max_length=self.max_len,\n",
    "        )\n",
    "\n",
    "        # tags to ids\n",
    "        self.tag_to_id = tag_to_id\n",
    "        self.encoded_labels = self.convert_labels_to_ids()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'input_ids': self.encoded_sentences['input_ids'][index],\n",
    "            'attention_mask': self.encoded_sentences['attention_mask'][index],\n",
    "            'labels': self.encoded_labels[index]\n",
    "        }\n",
    "    \n",
    "        def convert_labels_to_ids(self):\n",
    "            \n",
    "            # initialize encoded_labels has shape (num_sentences, max_len) with all is id of <PAD> tag\n",
    "            PAD_ID = self.tag_to_id['<PAD>']\n",
    "            encoded_labels = np.ones((len(self.labels), self.max_len)) * PAD_ID\n",
    "            # loop through all labels of sentences and convert to ids\n",
    "            for i, label in enumerate(self.labels):\n",
    "                # loop through all labels of sentence\n",
    "                for j, tag in enumerate(label):\n",
    "                    encoded_labels[i][j] = self.tag_to_id[tag]\n",
    "            \n",
    "            # convert to tensor\n",
    "            encoded_labels = torch.tensor(encoded_labels, dtype=torch.long, device=device)\n",
    "            print(encoded_labels)\n",
    "                    \n",
    "            return encoded_labels\n",
    "        \n",
    "\n",
    "train_dataset = SpanDetectionDataset(train_sentences, train_labels, tag_to_id, tokenizer)\n",
    "dev_dataset = SpanDetectionDataset(dev_sentences, dev_labels, tag_to_id, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader tensorflow\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext\n",
    "\n",
    "# # Load the pre-trained model\n",
    "# embedding_model = fasttext.load_model('pretrained-weights/cc.vi.300.bin')\n",
    "\n",
    "# vocabulary = tokenizer.get_vocabulary()\n",
    "# vector_dim = embedding_model.get_dimension()\n",
    "\n",
    "# embedding_matrix = np.zeros((len(vocabulary), vector_dim))\n",
    "# for i, word in enumerate(vocabulary):\n",
    "#         embedding_matrix[i] = embedding_model.get_word_vector(word)\n",
    "\n",
    "# embedding_matrix_file = 'embedding/embedding_matrix.npy'\n",
    "\n",
    "# np.save(embedding_matrix_file, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding\n",
    "# embedding_maxtrix = np.load('embedding/embedding_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "\n",
    "# def argmax(vec):\n",
    "#     # return the argmax as a python int\n",
    "#     _, idx = torch.max(vec, 1)\n",
    "#     return idx.item()\n",
    "\n",
    "\n",
    "# def prepare_sequence(seq, to_ix):\n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "#     return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# # Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "# def log_sum_exp(vec):\n",
    "#     max_score = vec[0, argmax(vec)]\n",
    "#     max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "#     return max_score + \\\n",
    "#         torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "# class BiLSTM_CRF(nn.Module):\n",
    "#     def __init__(self, vocab_size, tag_to_id, batch_size, embedding_matrix=None, embedding_dim=None, hidden_dim=200, units='lstm', droput=0.2, recurrent_dropout=0.2, max_len=MAX_LEN):\n",
    "#         super(BiLSTM_CRF, self).__init__()\n",
    "\n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.tag_to_ix = tag_to_id\n",
    "#         self.tagset_size = len(tag_to_id)\n",
    "\n",
    "#         self.max_len = max_len\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#         # check embedding matrix and embedding dimension\n",
    "#         if embedding_matrix is None and embedding_dim is None:\n",
    "#             raise ValueError('You must provide either embedding matrix or embedding dimension')\n",
    "#         if embedding_matrix is not None and embedding_dim is not None:\n",
    "#             raise ValueError('You must provide either embedding matrix or embedding dimension, not both')\n",
    "        \n",
    "#         if embedding_matrix is None:\n",
    "#             self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "#         if embedding_matrix is not None:\n",
    "#             self.word_embeds = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "\n",
    "#         num_layers = 1\n",
    "#         if units == 'lstm':\n",
    "#             self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, bidirectional=True, dropout=recurrent_dropout, num_layers=num_layers)\n",
    "#         elif units == 'gru':\n",
    "#             self.lstm = nn.GRU(embedding_dim, hidden_dim // 2, bidirectional=True, dropout=recurrent_dropout, num_layers=num_layers)\n",
    "#         elif units == 'rnn':\n",
    "#             self.lstm = nn.RNN(embedding_dim, hidden_dim // 2, bidirectional=True, dropout=recurrent_dropout, num_layers=num_layers)\n",
    "#         else:\n",
    "#             raise ValueError('Invalid unit type, must be one of \"lstm\", \"gru\", \"rnn\"')\n",
    "        \n",
    "#         self.hidden2tag = nn.Linear(hidden_dim, len(self.tag_to_ix))\n",
    "\n",
    "#         # self.dropout = nn.Dropout(droput)\n",
    "\n",
    "#         self.transitions = nn.Parameter(\n",
    "#             torch.randn(self.tagset_size, self.tagset_size).to(device)\n",
    "#             )\n",
    "\n",
    "#         self.transitions.data[tag_to_id[START_TAG], :] = -10000\n",
    "#         self.transitions.data[:, tag_to_id[STOP_TAG]] = -10000\n",
    "\n",
    "#         self.hidden = self.init_hidden()\n",
    "\n",
    "#     def init_hidden(self):\n",
    "#         return (torch.randn(2, self.max_len, self.hidden_dim // 2).to(device),\n",
    "#                 torch.randn(2, self.max_len, self.hidden_dim // 2).to(device))\n",
    "    \n",
    "#     def _forward_alg(self, feats):\n",
    "#         # Do the forward algorithm to compute the partition function\n",
    "#         init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "#         # START_TAG has all of the score.\n",
    "#         init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "#         # Wrap in a variable so that we will get automatic backprop\n",
    "#         forward_var = init_alphas\n",
    "\n",
    "#         # Iterate through the sentence\n",
    "#         for feat in feats:\n",
    "#             alphas_t = []  # The forward tensors at this timestep\n",
    "#             for next_tag in range(self.tagset_size):\n",
    "#                 # broadcast the emission score: it is the same regardless of\n",
    "#                 # the previous tag\n",
    "#                 emit_score = feat[next_tag].view(\n",
    "#                     1, -1).expand(1, self.tagset_size)\n",
    "#                 # the ith entry of trans_score is the score of transitioning to\n",
    "#                 # next_tag from i\n",
    "#                 trans_score = self.transitions[next_tag].view(1, -1)\n",
    "#                 # The ith entry of next_tag_var is the value for the\n",
    "#                 # edge (i -> next_tag) before we do log-sum-exp\n",
    "#                 next_tag_var = forward_var + trans_score + emit_score\n",
    "#                 # The forward variable for this tag is log-sum-exp of all the\n",
    "#                 # scores.\n",
    "#                 alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "#             forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "#         terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "#         alpha = log_sum_exp(terminal_var)\n",
    "#         return alpha\n",
    "    \n",
    "#     def _get_lstm_features(self, sentence):\n",
    "#         self.hidden = self.init_hidden()\n",
    "#         # embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "#         embeds = self.word_embeds(sentence)\n",
    "\n",
    "#         # print(embeds.shape)\n",
    "#         # print(self.hidden[0].shape, self.hidden[1].shape)\n",
    "        \n",
    "#         lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "\n",
    "#         # print(lstm_out.shape, self.hidden[0].shape, self.hidden[1].shape)\n",
    "        \n",
    "#         # lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "\n",
    "#         lstm_feats = self.hidden2tag(lstm_out)\n",
    "\n",
    "#         # lstm_feats = self.dropout(lstm_feats)\n",
    "#         return lstm_feats\n",
    "    \n",
    "#     def _score_sentence(self, feats, tags):\n",
    "#         # Gives the score of a provided tag sequence\n",
    "#         score = torch.zeros(1, device=device)\n",
    "#         tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long, device=device), tags])\n",
    "#         for i, feat in enumerate(feats):\n",
    "#             score = score + \\\n",
    "#                 self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "#         score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "#         return score\n",
    "\n",
    "#     def _viterbi_decode(self, feats):\n",
    "#         backpointers = []\n",
    "\n",
    "#         # Initialize the viterbi variables in log space\n",
    "#         init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "#         init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "#         # forward_var at step i holds the viterbi variables for step i-1\n",
    "#         forward_var = init_vvars\n",
    "#         for feat in feats:\n",
    "#             bptrs_t = []  # holds the backpointers for this step\n",
    "#             viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "#             for next_tag in range(self.tagset_size):\n",
    "#                 # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "#                 # previous step, plus the score of transitioning\n",
    "#                 # from tag i to next_tag.\n",
    "#                 # We don't include the emission scores here because the max\n",
    "#                 # does not depend on them (we add them in below)\n",
    "#                 next_tag_var = forward_var + self.transitions[next_tag]\n",
    "#                 best_tag_id = argmax(next_tag_var)\n",
    "#                 bptrs_t.append(best_tag_id)\n",
    "#                 viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "#             # Now add in the emission scores, and assign forward_var to the set\n",
    "#             # of viterbi variables we just computed\n",
    "#             forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "#             backpointers.append(bptrs_t)\n",
    "\n",
    "#         # Transition to STOP_TAG\n",
    "#         terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "#         best_tag_id = argmax(terminal_var)\n",
    "#         path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "#         # Follow the back pointers to decode the best path.\n",
    "#         best_path = [best_tag_id]\n",
    "#         for bptrs_t in reversed(backpointers):\n",
    "#             best_tag_id = bptrs_t[best_tag_id]\n",
    "#             best_path.append(best_tag_id)\n",
    "#         # Pop off the start tag (we dont want to return that to the caller)\n",
    "#         start = best_path.pop()\n",
    "#         assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "#         best_path.reverse()\n",
    "#         return path_score, best_path\n",
    "\n",
    "#     def neg_log_likelihood(self, batch_sentence, tags):\n",
    "#         batch_feats = self._get_lstm_features(batch_sentence) #[batch_size, max_len, hidden_dim/2]\n",
    "\n",
    "#         batch_forward_score = torch.zeros(1, device=device)\n",
    "#         batch_gold_score = torch.zeros(1, device=device)\n",
    "        \n",
    "#         for feats, tag in zip(batch_feats, tags):\n",
    "#             forward_score = self._forward_alg(feats) # this function get input is [max_len, hidden_dim/2]\n",
    "#             gold_score = self._score_sentence(feats, tag)\n",
    "\n",
    "#             batch_forward_score += forward_score\n",
    "#             batch_gold_score += gold_score\n",
    "\n",
    "#         return batch_forward_score - batch_gold_score\n",
    "    \n",
    "#     def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "#         # Get the emission scores from the BiLSTM\n",
    "#         lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "#         # Find the best path, given the features.\n",
    "#         batch_score, batch_tag_seq = torch.zeros(self.batch_size, device=device), torch.zeros(self.batch_size, device=device)\n",
    "        \n",
    "#         for feats in lstm_feats:\n",
    "#             score, tag_seq = self._viterbi_decode(feats)\n",
    "#             batch_score += score\n",
    "#             batch_tag_seq += tag_seq\n",
    "\n",
    "#         return batch_score, batch_tag_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Span detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x):\n",
    "    \"\"\"calculate log(sum(exp(x))) = max(x) + log(sum(exp(x - max(x))))\n",
    "    \"\"\"\n",
    "    max_score = x.max(-1)[0]\n",
    "    return max_score + (x - max_score.unsqueeze(-1)).exp().sum(-1).log()\n",
    "\n",
    "\n",
    "IMPOSSIBLE = -1e4\n",
    "\n",
    "\n",
    "class CRF(nn.Module):\n",
    "    \"\"\"General CRF module.\n",
    "    The CRF module contain a inner Linear Layer which transform the input from features space to tag space.\n",
    "\n",
    "    :param in_features: number of features for the input\n",
    "    :param num_tag: number of tags. DO NOT include START, STOP tags, they are included internal.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, num_tags):\n",
    "        super(CRF, self).__init__()\n",
    "\n",
    "        self.num_tags = num_tags + 2\n",
    "        self.start_idx = self.num_tags - 2\n",
    "        self.stop_idx = self.num_tags - 1\n",
    "\n",
    "        self.fc = nn.Linear(in_features, self.num_tags)\n",
    "\n",
    "        # transition factor, Tij mean transition from j to i\n",
    "        self.transitions = nn.Parameter(torch.randn(self.num_tags, self.num_tags), requires_grad=True)\n",
    "        self.transitions.data[self.start_idx, :] = IMPOSSIBLE\n",
    "        self.transitions.data[:, self.stop_idx] = IMPOSSIBLE\n",
    "\n",
    "    def forward(self, features, masks):\n",
    "        \"\"\"decode tags\n",
    "\n",
    "        :param features: [B, L, C], batch of unary scores\n",
    "        :param masks: [B, L] masks\n",
    "        :return: (best_score, best_paths)\n",
    "            best_score: [B]\n",
    "            best_paths: [B, L]\n",
    "        \"\"\"\n",
    "        features = self.fc(features)\n",
    "        return self.__viterbi_decode(features, masks[:, :features.size(1)].float())\n",
    "\n",
    "    def loss(self, features, ys, masks):\n",
    "        \"\"\"negative log likelihood loss\n",
    "        B: batch size, L: sequence length, D: dimension\n",
    "\n",
    "        :param features: [B, L, D]\n",
    "        :param ys: tags, [B, L]\n",
    "        :param masks: masks for padding, [B, L]\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        features = self.fc(features)\n",
    "\n",
    "        L = features.size(1)\n",
    "        masks_ = masks[:, :L].float()\n",
    "\n",
    "        forward_score = self.__forward_algorithm(features, masks_)\n",
    "        gold_score = self.__score_sentence(features, ys[:, :L].long(), masks_)\n",
    "        loss = (forward_score - gold_score).mean()\n",
    "        return loss\n",
    "\n",
    "    def __score_sentence(self, features, tags, masks):\n",
    "        \"\"\"Gives the score of a provided tag sequence\n",
    "\n",
    "        :param features: [B, L, C]\n",
    "        :param tags: [B, L]\n",
    "        :param masks: [B, L]\n",
    "        :return: [B] score in the log space\n",
    "        \"\"\"\n",
    "        B, L, C = features.shape\n",
    "\n",
    "        # emission score\n",
    "        emit_scores = features.gather(dim=2, index=tags.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # transition score\n",
    "        start_tag = torch.full((B, 1), self.start_idx, dtype=torch.long, device=tags.device)\n",
    "        tags = torch.cat([start_tag, tags], dim=1)  # [B, L+1]\n",
    "        trans_scores = self.transitions[tags[:, 1:], tags[:, :-1]]\n",
    "\n",
    "        # last transition score to STOP tag\n",
    "        last_tag = tags.gather(dim=1, index=masks.sum(1).long().unsqueeze(1)).squeeze(1)  # [B]\n",
    "        last_score = self.transitions[self.stop_idx, last_tag]\n",
    "\n",
    "        score = ((trans_scores + emit_scores) * masks).sum(1) + last_score\n",
    "        return score\n",
    "\n",
    "    def __viterbi_decode(self, features, masks):\n",
    "        \"\"\"decode to tags using viterbi algorithm\n",
    "\n",
    "        :param features: [B, L, C], batch of unary scores\n",
    "        :param masks: [B, L] masks\n",
    "        :return: (best_score, best_paths)\n",
    "            best_score: [B]\n",
    "            best_paths: [B, L]\n",
    "        \"\"\"\n",
    "        B, L, C = features.shape\n",
    "\n",
    "        bps = torch.zeros(B, L, C, dtype=torch.long, device=features.device)  # back pointers\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        max_score = torch.full((B, C), IMPOSSIBLE, device=features.device)  # [B, C]\n",
    "        max_score[:, self.start_idx] = 0\n",
    "\n",
    "        for t in range(L):\n",
    "            mask_t = masks[:, t].unsqueeze(1)  # [B, 1]\n",
    "            emit_score_t = features[:, t]  # [B, C]\n",
    "\n",
    "            # [B, 1, C] + [C, C]\n",
    "            acc_score_t = max_score.unsqueeze(1) + self.transitions  # [B, C, C]\n",
    "            acc_score_t, bps[:, t, :] = acc_score_t.max(dim=-1)\n",
    "            acc_score_t += emit_score_t\n",
    "            max_score = acc_score_t * mask_t + max_score * (1 - mask_t)  # max_score or acc_score_t\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        max_score += self.transitions[self.stop_idx]\n",
    "        best_score, best_tag = max_score.max(dim=-1)\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_paths = []\n",
    "        bps = bps.cpu().numpy()\n",
    "        for b in range(B):\n",
    "            best_tag_b = best_tag[b].item()\n",
    "            seq_len = int(masks[b, :].sum().item())\n",
    "\n",
    "            best_path = [best_tag_b]\n",
    "            for bps_t in reversed(bps[b, :seq_len]):\n",
    "                best_tag_b = bps_t[best_tag_b]\n",
    "                best_path.append(best_tag_b)\n",
    "            # drop the last tag and reverse the left\n",
    "            best_paths.append(best_path[-2::-1])\n",
    "\n",
    "        return best_score, best_paths\n",
    "\n",
    "    def __forward_algorithm(self, features, masks):\n",
    "        \"\"\"calculate the partition function with forward algorithm.\n",
    "        TRICK: log_sum_exp([x1, x2, x3, x4, ...]) = log_sum_exp([log_sum_exp([x1, x2]), log_sum_exp([x3, x4]), ...])\n",
    "\n",
    "        :param features: features. [B, L, C]\n",
    "        :param masks: [B, L] masks\n",
    "        :return:    [B], score in the log space\n",
    "        \"\"\"\n",
    "        B, L, C = features.shape\n",
    "\n",
    "        scores = torch.full((B, C), IMPOSSIBLE, device=features.device)  # [B, C]\n",
    "        scores[:, self.start_idx] = 0.\n",
    "        trans = self.transitions.unsqueeze(0)  # [1, C, C]\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for t in range(L):\n",
    "            emit_score_t = features[:, t].unsqueeze(2)  # [B, C, 1]\n",
    "            score_t = scores.unsqueeze(1) + trans + emit_score_t  # [B, 1, C] + [1, C, C] + [B, C, 1] => [B, C, C]\n",
    "            score_t = log_sum_exp(score_t)  # [B, C]\n",
    "\n",
    "            mask_t = masks[:, t].unsqueeze(1)  # [B, 1]\n",
    "            scores = score_t * mask_t + scores * (1 - mask_t)\n",
    "        scores = log_sum_exp(scores + self.transitions[self.stop_idx])\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_id, batch_size, embedding_matrix=None, embedding_dim=None, hidden_dim=200, units='lstm', recurrent_dropout=0.2, max_len=MAX_LEN):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_id\n",
    "        self.tagset_size = len(tag_to_id)\n",
    "\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # check embedding matrix and embedding dimension\n",
    "        if embedding_matrix is None and embedding_dim is None:\n",
    "            raise ValueError('You must provide either embedding matrix or embedding dimension')\n",
    "        if embedding_matrix is not None and embedding_dim is not None:\n",
    "            raise ValueError('You must provide either embedding matrix or embedding dimension, not both')\n",
    "        \n",
    "        if embedding_matrix is None:\n",
    "            self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        if embedding_matrix is not None:\n",
    "            self.word_embeds = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "\n",
    "        num_layers = 1\n",
    "        if units == 'lstm':\n",
    "            UNIT = nn.LSTM\n",
    "        elif units == 'gru':\n",
    "            UNIT = nn.GRU\n",
    "        elif units == 'rnn':\n",
    "            UNIT = nn.RNN\n",
    "        else:\n",
    "            raise ValueError('Invalid unit type, must be one of \"lstm\", \"gru\", \"rnn\"')\n",
    "        \n",
    "        self.lstm = UNIT(embedding_dim, hidden_dim // 2, bidirectional=True, dropout=recurrent_dropout, num_layers=num_layers)\n",
    "        \n",
    "        # self.hidden2tag = nn.Linear(hidden_dim, len(self.tag_to_ix))\n",
    "\n",
    "        self.crf = CRF(hidden_dim, self.tagset_size)\n",
    "    \n",
    "    def __build_features(self, sentences):\n",
    "        masks = sentences.gt(0)\n",
    "        embeds = self.word_embeds(sentences.long())\n",
    "\n",
    "        seq_length = masks.sum(1)\n",
    "        sorted_seq_length, perm_idx = seq_length.sort(descending=True)\n",
    "        embeds = embeds[perm_idx, :]\n",
    "\n",
    "        pack_sequence = pack_padded_sequence(embeds, lengths=sorted_seq_length.to('cpu'), batch_first=True)\n",
    "        packed_output, _ = self.lstm(pack_sequence)\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        _, unperm_idx = perm_idx.sort()\n",
    "        lstm_out = lstm_out[unperm_idx, :]\n",
    "\n",
    "        return lstm_out, masks\n",
    "    \n",
    "    def loss(self, xs, tags):\n",
    "        features, masks = self.__build_features(xs)\n",
    "        loss = self.crf.loss(features, tags, masks=masks)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, xs):\n",
    "        features, masks = self.__build_features(xs)\n",
    "        scores, tag_seq = self.crf(features, masks)\n",
    "        return scores, tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hii\\miniconda3\\envs\\absa\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\CLOUDX\\Courses\\nlp\\aspect-based-sentiment-analysis\\train_stage1_torch.ipynb Cell 22\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train_stage1_torch.ipynb#X31sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train_stage1_torch.ipynb#X31sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_model, train_loss, dev_loss\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train_stage1_torch.ipynb#X31sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m model, train_loss, dev_loss \u001b[39m=\u001b[39m train_model((train_dataloader, dev_dataloader), epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, weight_decay\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, early_stopping\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32md:\\CLOUDX\\Courses\\nlp\\aspect-based-sentiment-analysis\\train_stage1_torch.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train_stage1_torch.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train_stage1_torch.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train_stage1_torch.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train_stage1_torch.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m train_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CLOUDX/Courses/nlp/aspect-based-sentiment-analysis/train_stage1_torch.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(dataloader, epochs=20, lr=0.01, weight_decay=0.01, early_stopping=5):\n",
    "    train_loader, dev_loader = dataloader\n",
    "\n",
    "    model = BiLSTM_CRF(vocab_size=len(tokenizer.get_vocab()), tag_to_id=tag_to_id, batch_size=BATCH_SIZE, embedding_dim=300)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = model.loss(input_ids, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        dev_loss = 0\n",
    "        for batch in dev_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            loss = model.loss(input_ids, labels)\n",
    "\n",
    "            dev_loss += loss.item()\n",
    "        \n",
    "        dev_loss /= len(dev_loader)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, train_loss: {train_loss}, dev_loss: {dev_loss}')\n",
    "\n",
    "        # calculate F1 score\n",
    "\n",
    "        # early stopping\n",
    "        if dev_loss < best_loss:\n",
    "            best_loss = dev_loss\n",
    "            best_model = model\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        \n",
    "        if early_stopping_counter >= early_stopping:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    return best_model, train_loss, dev_loss\n",
    "\n",
    "model, train_loss, dev_loss = train_model((train_dataloader, dev_dataloader), epochs=20, lr=0.001, weight_decay=0.01, early_stopping=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save_pretrained('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_data = read_jsonl_to_dataframe(TEST_PATH)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "sentence = test_data.text[idx]\n",
    "label = test_data.labels[idx]\n",
    "\n",
    "def end_to_end_predict(sentence):\n",
    "    # tokenize sentence\n",
    "    tokenized_sentence = tokenizer(sentence, return_tensors='pt', padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    # predict\n",
    "    scores, tag_seq = model(tokenized_sentence['input_ids'].to(device))\n",
    "    # convert tag_seq to tag\n",
    "    tag_seq = tag_seq[0].cpu().numpy()\n",
    "    tag_seq = [id_to_tag[tag] for tag in tag_seq]\n",
    "    # convert to list of (word, tag)\n",
    "    words = tokenizer.convert_ids_to_tokens(tokenized_sentence['input_ids'][0])\n",
    "    words = words[1:-1]\n",
    "    return list(zip(words, tag_seq))\n",
    "\n",
    "end_to_end_predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
